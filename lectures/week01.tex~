\documentclass{hertieteaching}
\usepackage{cancel}

\title{Introduction: Causation}

\begin{document}

\maketitle

\begin{frame}{How to think about causation}

We're going to use three complementary frameworks for thinking systematically about causation
\begin{enumerate}
  \item Structural equations
  \item Graphs
  \item Potential outcomes
\end{enumerate}

These correspond to different focuses
\begin{enumerate}
  \item Nature: The mechanisms a.k.a. `the Science'
  \item Nature's joints: How \textit{variables} relate to one another in these mechanisms
  \item Nature's creatures: How \textit{cases} relate to one another 
\end{enumerate}


\end{frame}

\begin{frame}{How to think about causation}

What we get to work with is\ldots \textit{data}: columns of numbers organised into cases and variables, and their 
associations
\begin{itemize}
  \item The joint probability distribution of variables
  \item All the conditional distributions
  \item All the independence relationships
\end{itemize}

All of that stuff is either 
\begin{enumerate}
  \item generated by nature according to some causal structure that we'd love to know about, or 
  \item generated by nature according to some \textit{other} structures that look like noise from this one
  \item Random noise
\end{enumerate}

Hint: Unless you are doing quantum physics, you can assume 3 is just 2.

% Noise is just signal you haven't met yet

\end{frame}

\begin{frame}{Samples and populations}

Usually the data we have is
\begin{itemize}
  \item a sample from a population
  \item a population, which could have been different
  \item a population, which we can only measure imperfectly
\end{itemize}
(For many statistical purposes these are treated the same, or at least very similarly)

Consequently many of those observed associations will be noisy version of the true ones

~\\

But we have causal purposes, which are different, and we will assume we have the population
\begin{itemize}
\item things are plenty hard enough even then  
\end{itemize}

\end{frame}

\begin{frame}{`The Science'}

What do we need to assume about the science?

We will assume 
\begin{itemize}
  \item we can express it all in equations that relate a variable on the left hand side (a `dependent' variable) to one or more variables on the right hand side (the `explanatory' variables)
  \item Each equation represents a distinct \textit{mechanism}
  \item The equation set is complete up to random noise
\end{itemize}

We can be fairly vague here because causal inference doesn't care about your subject matter (much)

\end{frame}
\begin{frame}{Representational constraints}

But there are some constraints (for this course)
\begin{itemize}
  \item We cannot separately things that are logically connected (duh)
  \item 
\end{itemize}




\end{frame}


\end{document}
 
%* you may doubt that the world is made up of deterministic structural equations - that's ok, we can deal with extra random causes affecting all the bits of our equations. we just need to assume that they're not systematically related to the things we've got in the equations set.
%* if they are systematically related, then our equations are incomplete.
%
%* equations are the full physical story about what caused what, we don't usually know this. 
%* we don't need to assume that they are linear or any particular form
%* we do need to assume that at least some of them are are modular, (that they consitutitute separable 'mechanisms'), that we can imagine intervening on or generally messed with separately from outside the system.
%* there are of course some constraints here: we cannot alter the per capita gdp of a country while keeping the population and its output the same, but these are pretty logical
%* note the interpretation of the coefficients: they are causal (reverse equation structures either don't work or represent a different mechanism pushing in the 'other' direction)
%* we are often willing to abstract from the functional forms to the equation structure
%* one way to do this is to draw a graph showing the independencies (not the dependencies) between the mechanisms
%* this implicitly connects variables not cases
%* another way is to consider potential outcomes, this is the 'extensive form' (or the 'game tree') of the structural equations. it is the garden of the forking paths
%* let's talk about the graph first: it shows what is associated with what. Specifically it implies independencies, dependencies, and conditional independencies.
%* Now might be a good time to remind yourself of how (conditional) independence works. 
%* We'll tend to write independence of X and as either P(Y | X) = P(Y) or equivalently P(X, Y) = P(X) * P(Y), or X indep Y, 
%* and independence of Y and X given G as P(Y | X, G) = P(Y | G) or P(X, Y | G) =  P(X | G) * P(Y | G), so Y indep X | G
%* the arrows in the graph represent the relationships in the equations. ends are outcomes, and connecting arrows indicate one or more of the equation.
%* note that we don't distinguish in the graph between 'interactions' where two or more variables depend on each other for their effects in a single equation and 
%* additive or multiplicative relationships where there are two separate components generating the outcome 
%* usually we are going to be interested in the effect of changing some variable X on another one Y. This is going to the causal effect of X on Y. In simple cases its going correspond to just one arrow 
%* in more complex cases it's going to be a all the paths between X and Y (because sometimes there are lots of ways to make Y change using X 
%* in even more complex cases we are interested in just one of the paths by which X affects Y 'holding all the others constant' (whatever that turns out to mean)
%* So what actually is the effect of X on Y? Well that depends on the equation(s) connecting these two together. Let's take a simple situation
%* The relationship is Y = a + b*X + e and X is 0 or 1
%* In this case the effect of X on Y is b. Why's that?
%* Because if we stepped into the little linear world we've described and adjusted X from 0 to 1 then we would expect Y to be b higher.
%* In the graph of this world this means that we have decoupled X from all the equations that would normally determine its value no longer get to do that, because we do
%* this corresponds to breaking the graph by removing all the arrows incoming to X, (equivalently setting X to a constant 0 or 1 in the equation set)
%* clearly if X and Y were jointly determined by some other variable Z then consequence for Y of changing X is not the same as the association we would see in the data between X and Y
%* Pearl describes this difference as the difference between set (or 'do') X and when we just 'see' X is 0 (or 1)
%* the causal effect is the differences in nY when we set X and this only sometimes corresponds to the differences when we see annd compare different values of X.
%* When we can arrange things such that what we see is also what happen if we set, then we have 'identified' the causal effect. That is we have made it visible in the world without having to think about some other world where the connections are all different.
%* non-parametrics: one nice thing about thinking about graphs rather than the equations is that we are not going to need to worry about the exact form of all the equations, in the sense that we will often be able to identify causal relationships regardless.
%* this is, both nice (because hey, causal relations from observational data!), not magic (because if we're wrong about the graph structure too, in ways that have no consequences that can be seen in the data, then we can mess up and never know), conservative (because if we are willing to make assumptions about the functional forms, e.g. monotonicity of some relationship, then we can identify more stuff than with graphs alone.
%* Let's take a look at the alternative way to think about causal effects, potential outcomes
%* First, consider the causal effect of X on Y for me. We can think of this as the difference between Y if X=0 for me and what Y would have been had X (counterfactually) been 1. 
%* Awesome, there's a definition of the ordinary language sense of causal effect
%* Let's give these potential outcomes (one of which will eventually be the actual outcome while the other remains the counterfactual outcome) some names. Actually the naming scheme differs and we can't do much about that. Try Y^{X=0} for the outcome if X is set to 0. 
%* Remember this is not the value of Y when X happens to be 0.
%* But they are, related, obviously. In this binary case like this: Y = X Y^1 + (1-X) Y^0, which is a fancy math way of making sure that if your X really is 0 then Y = Y^0 and if its 1 then Y = Y^1.
%* This is called consistency and we need to anchor the potential outcomes to reality
%* Actually a graph anchors them to reality somewhat as we'll see later, but if we don't work with the graph, as some economists insist on doing then we need some tethering.
%* The tricky thing about potential outcomes is that we can and do treat things like Y^X like regular variables. We can ask if Y^0 is independent of Z for example. "is what would happen to Y if your X was 0 more predictable knowing your Z?" If Y^0 indep Z then it is.
%* In practice what we nearly always end up wondering is whether the range of things that would happen if your X=1 is the same as the range of things that would happen if your X=0.
%* The range of things that could happen to your Y is the set of potential outcomes Y^0 and Y^1 so it could well be that they are jointly independent of X
%* Feels a bit weird to say that to say that Y^0 and Y^1 are different is to say that X affects Y. So how could they be independent? Well, they aren't. 
%* (We know they're not because he recipe for figuring out what Y is depends on X, in that consistency formula we say earlier)
%* What we're really saying is that we wouldn't predict things to go X to have different possible effects depending on your actual X assignment.
%* One very useful implication of this kind of independence between Y^0, Y^1 and X is that it allows us to say that comparisons between actual Ys when X=1 and actual Ys when X=0 tell us about the causal effect of X on Y.
%* Let's say a few things about causal effects in this framework. The we were thinking about graphs we identified the causal effect as the resulting changing in an outcome resulting from intervening on the system of equations (decoupling X from its parents in the graph), setting X to some value, and seeing what happened to Y.
%* In the potential outcomes we can do something equivalent by defining an average treatment effect - the average of Y^1 - Y^0 over the whole population.
%* Remember that half of these outcomes are never observed. However, if we have exchangeability then the actual outcomes of the treated groups tell us, at least on average, what the control group would have done had they been treated. And vice versa
%* Meaning that the causal effect (a function of Y^0 and Y^1) is identified by the mean difference of completely observed Ys.
%* Exchangeability is rather unlikely in practice (maybe perfectly randomised trials are an example of where it's true), but we can loosen the requirements to say that Y^1, Y^0 indep X | Z for some plausible Z variables.
%* Here we are admitting that sometimes the range of possibilities for Y is actually different depending on whether your X, /but/ that this is because of Z, in the sense that Z both predicts your X value and also what Y you will get, but that happily once we know what Z you have Y^1, Y^0 indep X are all nicely and exchangeable again.
%* Note that the effect of X on Y could be quite different for different values of Z, opposite even, so it somewhat intuitive that when we ask the average causal effect we are going to want to average over the effects at each level of Z weighted by the proportion of cases at each level. 
%* In practice we usually do with with a regression model and call it 'controlling for Z', but it's actually the Z weighted effect average we want.
%* Sometimes we also want Z specific effects, in which case we can just throw away all the cases with Z values we're not interested in and examine the X-Y effect in what's left.
%* This is an example of a useful but subtle concept in causal inference, which is that keeping a bunch of observations and throwing the rest away is the same as conditioning on (controlling for) whatever variable(s) you used to decide who to keep.
%* This becomes important when some data is just missing and we want to model the mechanism by which it managed each case managed to stay in the data set that we see.
%* Clearly you can't get an ATE when you only consider Z=1 but hey, you get a 'subgroup' effect for Z=1.
%* We'll ponder all this further in later weeks
%* OK so we looked at three approaches to representing causation: equations, graphs, and potential outcomes. Let's try to put the graphs and potential outcomes together.
%* Let's start with this mysterious Y^1, Y^0 indep X | Z idea. When would exchangeability / independence fail but conditional independence be true? 
%* We kind of gave it away earlier. In a graph that'd be when Z is a common cause of X and Y. picture of graph
%* So when you see conditional exchangeability that's the sort of graph structure that would make it true.
%* Let's connect this graph a bit more closely to the potential outcomes. we'll work with binary Z and X to make things easier to write
%* Say Z=1 makes X=1 more likely that X=0. Now we don't have independence because if I know whether Z=1 then I can predict that X=1 is more likely
%* This isn't a problem for us unless Z also affects Y (I mean, X has a cause - most things do! doesn't mean we can't compare their effects on things) and then its a problem. confounding to give it a name 
%* Now in graph world we learn what the causal effect of X is by stepping into this happy triangular world and adjusting X ourselves, then looking at variation in Y.
%* Since we've decoupled X from the Z that usually causes it. 
%* In the graph we can do this by intervention, but some interventions are better than others. Perhaps the ideal one 
%* is to setting up some randomization, that is to recouple X to something that doesn't know anything about any Y (or Z for that matter) because it doesn't know anything about anything: picture
%* Here the lack of connection between the randomization device and Z and Y guarantees that independence holds. Not just conditional independence either - complete independence
%* We can also just condition on Z. If it has levels, that means breaking the data in to different values of Z and examining the X Y relations there. 
%* Within each level of Z, Z is a constant (duh) so it definitely didn't have any effect on Y, so each of those differences is X doing its thing.
%* That is another way to get exchangeability: conditioning.
%* There are actually a few more: we can indulge in a cunning weighting scheme too, and there are some unappreciated virtues of that plan, but they will have to wait for another day 
%* unfaithfulness: one quirk of this graph abstraction is that it only guarantees (conditional) independencies in the data
  
